{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wilds.datasets.rxrx1_dataset import RxRx1Dataset\n",
    "dataset = RxRx1Dataset(root_dir=\"D:\\\\Datasets\", download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from wilds.common.data_loaders import get_train_loader\n",
    "train_data = dataset.get_subset(\n",
    "    \"train\",\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.Resize((448, 448)), transforms.ToTensor()]\n",
    "    ),\n",
    ")\n",
    "train_loader = get_train_loader(\"standard\", train_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = dataset.get_subset(\n",
    "    \"val\",\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.Resize((448, 448)), transforms.ToTensor()]\n",
    "    ),\n",
    ")\n",
    "test_data = dataset.get_subset(\n",
    "    \"test\",\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.Resize((448, 448)), transforms.ToTensor()]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 125510\n",
      "Train set size: 40612\n",
      "Validation set size: 9854\n",
      "Test set size: 34432\n",
      "Train batches of 16 samples: 2539\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Train set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "print(f\"Train batches of 16 samples: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 448, 448]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for b in train_loader:\n",
    "\tx,y,metadata = b # sta roba sembra gi√† normalizzata\n",
    "\tprint(x.shape, y.shape)\n",
    "\tbreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on dataset\n",
    "- 1108 classes (different siRNA genes)\n",
    "- 4 plates of 308 wells each. In each well we have a different siRNA\n",
    "- In each plate we have\n",
    "\t- 30 control siRNA\n",
    "\t- 277 non-contron siRNA\n",
    "\t- 1 untreated well\n",
    "- Each well contains 2 images of 512x512x6\n",
    "- For each image, in the metadata we find:\n",
    "\t- the cell type\n",
    "\t- the experiment\n",
    "\t- the plate in the experiment\n",
    "\t- the location on the plate\n",
    "\t- the siRNA\n",
    "- Basically in each batch is refered to a particular cell type:\n",
    "\t- 24 batches for HUVEC\n",
    "\t- 11 batches for RPE\n",
    "\t- 11 batches for HepG2\n",
    "\t- 5 batches for U2OS\n",
    "- Each experiment is a set of 4 plates (i think experiment and batch are the same thing)\n",
    "- A single BATCH of experiments is a \"session\" where an operator did several experiments (plates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on solutions found in Kaggle\n",
    "- ArcFace loss is used in many solutions\n",
    "- In training, use domain(plate) aware batch sampling\n",
    "\t(otherwise batch norm fuks things up as it has to deal with \n",
    "\timages coming from different plates, so different colors, ecc...)\n",
    "- So we have to test with batching from same experiment, batch, plate, ecc...\n",
    "- This guy https://www.kaggle.com/competitions/recursion-cellular-image-classification/discussion/110335\n",
    "\thas a pretty simple solution, he normalizes on experiments.\n",
    "\tHe removes HUVEC05 cuz is to different from the rest.\n",
    "- We really need to understand the structure of the experiment, apparently there is a lot more than expected.\n",
    "\tThere is this caveat that was found out during the competition https://www.kaggle.com/c/recursion-cellular-image-classification/discussion/102905\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_nce_loss(features, batch_size):\n",
    "\tn_views = 2\t\n",
    "\ttemperature = 0.4\n",
    "\n",
    "\tlabels = torch.cat([torch.arange(batch_size) for i in range(n_views)], dim=0)\n",
    "\tlabels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "\n",
    "\tfeatures = F.normalize(features, dim=1)\n",
    "\n",
    "\tsimilarity_matrix = torch.matmul(features, features.T)\n",
    "\tassert similarity_matrix.shape == (\n",
    "\t    n_views * batch_size, n_views * batch_size)\n",
    "\tassert similarity_matrix.shape == labels.shape\n",
    "\n",
    "\t# discard the main diagonal from both: labels and similarities matrix\n",
    "\tmask = torch.eye(labels.shape[0], dtype=torch.bool)\n",
    "\tlabels = labels[~mask].view(labels.shape[0], -1)\n",
    "\tsimilarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "\t# assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "\t# select and combine multiple positives\n",
    "\tpositives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "\n",
    "\t# select only the negatives the negatives\n",
    "\tnegatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "\tlogits = torch.cat([positives, negatives], dim=1)\n",
    "\tlabels = torch.zeros(logits.shape[0], dtype=torch.long)\n",
    "\n",
    "\tlogits = logits / temperature\n",
    "\treturn logits, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "features = torch.rand(2*N,64)\n",
    "logits, labels = info_nce_loss(features, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "test = torch.zeros(size=(32,64))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
